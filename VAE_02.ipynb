{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f437af4",
   "metadata": {},
   "source": [
    "# Mohammed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05876f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import io\n",
    "import tensorflow as tf\n",
    "import ipywidgets as widgets\n",
    "from PIL import Image\n",
    "from IPython.display import display, clear_output\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.layers import Input, Dense, Lambda, Flatten, Reshape, Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras import backend as K\n",
    "import random\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual, VBox, HBox\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94fcdb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(directory):\n",
    "    images = []\n",
    "    for folder in os.listdir(directory):\n",
    "        emotion_folder = os.path.join(directory, folder)\n",
    "        if os.path.isdir(emotion_folder):\n",
    "            for file in os.listdir(emotion_folder):\n",
    "                img_path = os.path.join(emotion_folder, file)\n",
    "                img = load_img(img_path, color_mode='grayscale', target_size=(48, 48))\n",
    "                img = img_to_array(img)\n",
    "                img = img / 255.0 \n",
    "                images.append(img)\n",
    "    return np.array(images)\n",
    "\n",
    "train_data = load_data('FER2013/train')\n",
    "test_data = load_data('FER2013/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "532683f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (48, 48, 1)\n",
    "latent_dim = 6\n",
    "\n",
    "inputs = Input(shape=input_shape, name='encoder_input')\n",
    "x = Conv2D(32, 3, activation='relu', strides=2, padding='same')(inputs)\n",
    "x = Conv2D(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(16, activation='relu')(x)\n",
    "z_mean = Dense(latent_dim, name='z_mean')(x)\n",
    "z_log_var = Dense(latent_dim, name='z_log_var')(x)\n",
    "\n",
    "def sampling(args):\n",
    "    z_mean, z_log_var = args\n",
    "    batch = K.shape(z_mean)[0]\n",
    "    dim = K.int_shape(z_mean)[1]\n",
    "    epsilon = K.random_normal(shape=(batch, dim))\n",
    "    return z_mean + K.exp(0.5 * z_log_var) * epsilon\n",
    "\n",
    "z = Lambda(sampling, output_shape=(latent_dim,), name='z')([z_mean, z_log_var])\n",
    "\n",
    "\n",
    "encoder = Model(inputs, [z_mean, z_log_var, z], name='encoder')\n",
    "\n",
    "\n",
    "latent_inputs = Input(shape=(latent_dim,), name='z_sampling')\n",
    "x = Dense(12 * 12 * 64, activation='relu')(latent_inputs)\n",
    "x = Reshape((12, 12, 64))(x)\n",
    "x = Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x)\n",
    "x = Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x)\n",
    "outputs = Conv2DTranspose(1, 3, activation='sigmoid', padding='same', name='decoder_output')(x)\n",
    "\n",
    "\n",
    "decoder = Model(latent_inputs, outputs, name='decoder')\n",
    "\n",
    "\n",
    "outputs = decoder(encoder(inputs)[2])\n",
    "vae = Model(inputs, outputs, name='vae')\n",
    "\n",
    "reconstruction_loss = binary_crossentropy(K.flatten(inputs), K.flatten(outputs))\n",
    "reconstruction_loss *= input_shape[0] * input_shape[1]\n",
    "kl_loss = 1 + z_log_var - K.square(z_mean) - K.exp(z_log_var)\n",
    "kl_loss = K.sum(kl_loss, axis=-1)\n",
    "kl_loss *= -0.5\n",
    "vae_loss = K.mean(reconstruction_loss + kl_loss)\n",
    "vae.add_loss(vae_loss)\n",
    "vae.compile(optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b70e2c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1581.7686 - val_loss: 1581.7472\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 30s 33ms/step - loss: 1580.7819 - val_loss: 1580.5134\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 30s 33ms/step - loss: 1580.4949 - val_loss: 1580.7064\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 29s 33ms/step - loss: 1580.5476 - val_loss: 1581.5021\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 30s 33ms/step - loss: 1580.4771 - val_loss: 1580.5176\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1580.4114 - val_loss: 1580.5472\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 29s 33ms/step - loss: 1580.3633 - val_loss: 1580.3688\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1580.3157 - val_loss: 1580.4788\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 29s 33ms/step - loss: 1580.3082 - val_loss: 1580.5168\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1580.2808 - val_loss: 1580.4103\n",
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishraqmohammed/anaconda3/lib/python3.11/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "vae.fit(train_data, epochs=10, batch_size=32, validation_data=(test_data, None))\n",
    "vae.save('/vae_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f169f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1507.9957 - val_loss: 1483.1440\n",
      "Epoch 2/10\n",
      "898/898 [==============================] - 29s 33ms/step - loss: 1479.5790 - val_loss: 1478.7164\n",
      "Epoch 3/10\n",
      "898/898 [==============================] - 29s 33ms/step - loss: 1476.5156 - val_loss: 1476.6162\n",
      "Epoch 4/10\n",
      "898/898 [==============================] - 30s 34ms/step - loss: 1474.5189 - val_loss: 1475.6244\n",
      "Epoch 5/10\n",
      "898/898 [==============================] - 30s 34ms/step - loss: 1473.3389 - val_loss: 1474.6832\n",
      "Epoch 6/10\n",
      "898/898 [==============================] - 30s 33ms/step - loss: 1472.8971 - val_loss: 1474.1458\n",
      "Epoch 7/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1472.4929 - val_loss: 1473.2897\n",
      "Epoch 8/10\n",
      "898/898 [==============================] - 29s 33ms/step - loss: 1471.8890 - val_loss: 1473.1482\n",
      "Epoch 9/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1471.6251 - val_loss: 1476.5017\n",
      "Epoch 10/10\n",
      "898/898 [==============================] - 29s 32ms/step - loss: 1471.3086 - val_loss: 1472.4266\n",
      "WARNING:tensorflow:Found duplicated `Variable`s in Model's `weights`. This is usually caused by `Variable`s being shared by Layers in the Model. These `Variable`s will be treated as separate `Variable`s when the Model is restored. To avoid this, please save with `save_format=\"tf\"`.\n"
     ]
    }
   ],
   "source": [
    "def apply_mask(image, mask_size_ratio, mask_position):\n",
    "    h, w = image.shape[:2]\n",
    "    mask_size = int(min(h, w) * mask_size_ratio)\n",
    "    x = int(w * mask_position[0])\n",
    "    y = int(h * mask_position[1])\n",
    "    x_end = min(x + mask_size, w)\n",
    "    y_end = min(y + mask_size, h)\n",
    "    masked_image = image.copy()\n",
    "    masked_image[y:y_end, x:x_end] = 0\n",
    "    return masked_image\n",
    "\n",
    "def load_data_with_masks(directory):\n",
    "    images = []\n",
    "    for folder in os.listdir(directory):\n",
    "        emotion_folder = os.path.join(directory, folder)\n",
    "        if os.path.isdir(emotion_folder):\n",
    "            for file in os.listdir(emotion_folder):\n",
    "                img_path = os.path.join(emotion_folder, file)\n",
    "                img = load_img(img_path, color_mode='grayscale', target_size=(48, 48))\n",
    "                img = img_to_array(img)\n",
    "                img = img / 255.0  \n",
    "\n",
    "                \n",
    "                mask_size_ratio = random.uniform(0.1, 0.5)  \n",
    "                mask_position_x = random.uniform(0, 1)\n",
    "                mask_position_y = random.uniform(0, 1)\n",
    "                mask_position = (mask_position_x, mask_position_y)\n",
    "\n",
    "                masked_img = apply_mask(img, mask_size_ratio, mask_position)\n",
    "                images.append(masked_img)\n",
    "    return np.array(images)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data_masked = load_data_with_masks('FER2013/train')\n",
    "test_data_masked = load_data_with_masks('FER2013/test')\n",
    "\n",
    "input_shape = (48, 48, 1)  \n",
    "latent_dim = 6  \n",
    "\n",
    "\n",
    "inputs_2 = Input(shape=input_shape, name='encoder_input')\n",
    "x_2 = Conv2D(32, 3, activation='relu', strides=2, padding='same')(inputs_2)\n",
    "x_2 = Conv2D(64, 3, activation='relu', strides=2, padding='same')(x_2)\n",
    "x_2 = Flatten()(x_2)\n",
    "x_2 = Dense(16, activation='relu')(x_2)\n",
    "z_mean_2 = Dense(latent_dim, name='z_mean_2')(x_2)\n",
    "z_log_var_2 = Dense(latent_dim, name='z_log_var_2')(x_2)\n",
    "\n",
    "\n",
    "def sampling_2(args):\n",
    "    z_mean_2, z_log_var_2 = args\n",
    "    batch_2 = K.shape(z_mean_2)[0]\n",
    "    dim_2 = K.int_shape(z_mean_2)[1]\n",
    "    epsilon_2 = K.random_normal(shape=(batch_2, dim_2))\n",
    "    return z_mean_2 + K.exp(0.5 * z_log_var_2) * epsilon_2\n",
    "\n",
    "z_2 = Lambda(sampling_2, output_shape=(latent_dim,), name='z_2')([z_mean_2, z_log_var_2])\n",
    "\n",
    "\n",
    "encoder_2 = Model(inputs_2, [z_mean_2, z_log_var_2, z_2], name='encoder_2')\n",
    "\n",
    "\n",
    "latent_inputs_2 = Input(shape=(latent_dim,), name='z_sampling_2')\n",
    "x_2 = Dense(12 * 12 * 64, activation='relu')(latent_inputs_2)\n",
    "x_2 = Reshape((12, 12, 64))(x_2)\n",
    "x_2 = Conv2DTranspose(64, 3, activation='relu', strides=2, padding='same')(x_2)\n",
    "x_2 = Conv2DTranspose(32, 3, activation='relu', strides=2, padding='same')(x_2)\n",
    "outputs_2 = Conv2DTranspose(1, 3, activation='sigmoid', padding='same', name='decoder_output')(x_2)\n",
    "\n",
    "\n",
    "decoder_2 = Model(latent_inputs_2, outputs_2, name='decoder_2')\n",
    "\n",
    "\n",
    "outputs_2 = decoder_2(encoder_2(inputs_2)[2])\n",
    "vae_task2 = Model(inputs_2, outputs_2, name='vae_task2')\n",
    "\n",
    "\n",
    "reconstruction_loss_2 = binary_crossentropy(K.flatten(inputs_2), K.flatten(outputs_2))\n",
    "reconstruction_loss_2 *= input_shape[0] * input_shape[1]\n",
    "kl_loss_2 = 1 + z_log_var_2 - K.square(z_mean_2) - K.exp(z_log_var_2)\n",
    "kl_loss_2 = K.sum(kl_loss_2, axis=-1)\n",
    "kl_loss_2 *= -0.5\n",
    "vae_task2_loss = K.mean(reconstruction_loss_2 + kl_loss_2)\n",
    "vae_task2.add_loss(vae_task2_loss)\n",
    "vae_task2.compile(optimizer='adam')\n",
    "\n",
    "\n",
    "vae_task2.fit(train_data_masked, epochs=10, batch_size=32, validation_data=(test_data_masked, None))\n",
    "vae_task2.save('/vae_task2_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d472b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y_true, y_pred):\n",
    "    return np.mean((y_true - y_pred) ** 2)\n",
    "\n",
    "\n",
    "# Function to calculate Structural Similarity Index (SSIM)\n",
    "def calculate_ssim(y_true, y_pred):\n",
    "    return (y_true, y_pred, data_range==y_true.max() - y_true.min())\n",
    "\n",
    "\n",
    "# Function to calculate Peak Signal-to-Noise Ratio (PSNR)\n",
    "def calculate_psnr(y_true, y_pred):\n",
    "    return (y_true, y_pred, data_range==y_true.max() - y_true.min())\n",
    "\n",
    "\n",
    "def reconstruct_image(image,  vae_model):\n",
    "    image = image / 255.0\n",
    "    image = np.expand_dims(image, axis=2)\n",
    "    reconstructed_image = vae_model.predict(image[None, ...])[0]\n",
    "    mse = mean_squared_error(image, reconstructed_image )\n",
    "    ssim = calculate_ssim(image, reconstructed_image)\n",
    "    psnr = calculate_psnr(image, reconstructed_image)\n",
    "    print(\"MSE = \", mse)\n",
    "    print(\"ssim_score\",ssim)\n",
    "    print(\"psnr_score\", psnr)\n",
    "    return reconstructed_image.squeeze(axis=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e57872e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df9298e0c3e48e49c55e85bf706d1f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=0.0, description='Dim 1', max=3.0, min=-3.0), FloatSlider(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 100ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 8ms/step\n"
     ]
    }
   ],
   "source": [
    "l1 = widgets.FloatSlider(min=-3, max=3, step=0.1, description='Dim 1')\n",
    "l2 = widgets.FloatSlider(min=-3, max=3, step=0.1, description='Dim 2')\n",
    "l3 = widgets.FloatSlider(min=-3, max=3, step=0.1, description='Dim 3')\n",
    "l4 = widgets.FloatSlider(min=-3, max=3, step=0.1, description='Dim 4')\n",
    "l5 = widgets.FloatSlider(min=-3, max=3, step=0.1, description='Dim 5')\n",
    "l6 = widgets.FloatSlider(min=-3, max=3, step=0.1, description='Dim 6')\n",
    "\n",
    "\n",
    "image_widget = widgets.Image(format='png', width=300, height=400)\n",
    "\n",
    "\n",
    "def update_image(change):\n",
    "    latent_vector = np.array([[l1.value, l2.value, l3.value, l4.value, l5.value, l6.value]])\n",
    "    reconstructed_img = decoder.predict(latent_vector)\n",
    "    reconstructed_img = np.squeeze(reconstructed_img, axis=0)\n",
    "    reconstructed_img = (reconstructed_img * 255).astype(np.uint8)\n",
    "\n",
    "    \n",
    "    if reconstructed_img.ndim == 3:\n",
    "        reconstructed_img = reconstructed_img[:, :, 0]\n",
    "\n",
    "    \n",
    "    img = Image.fromarray(reconstructed_img, 'L')\n",
    "    with io.BytesIO() as output:\n",
    "        img.save(output, format=\"PNG\")\n",
    "        contents = output.getvalue()\n",
    "    image_widget.value = contents\n",
    "\n",
    "\n",
    "l1.observe(update_image, names='value')\n",
    "l2.observe(update_image, names='value')\n",
    "l3.observe(update_image, names='value')\n",
    "l4.observe(update_image, names='value')\n",
    "l5.observe(update_image, names='value')\n",
    "l6.observe(update_image, names='value')\n",
    "\n",
    "\n",
    "sliders = widgets.VBox([l1, l2, l3, l4, l5, l6])\n",
    "ui = widgets.HBox([sliders, image_widget])\n",
    "display(ui)\n",
    "\n",
    "\n",
    "update_image(None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00185d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56b959a1839f44bf9dd7a65bf68d8a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=0.0, description='Size Factor:', max=0.5, step=0.05), FloatSli…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def load_my_model(path):\n",
    "    model = load_model(path)\n",
    "    return model\n",
    "\n",
    "\n",
    "vae = load_my_model(\"vae_model.h5\")\n",
    "vae_task2 = load_my_model(\"vae_task2_model.h5\")\n",
    "\n",
    "def to_array(image):\n",
    "\n",
    "    image = Image.open(io.BytesIO(image))\n",
    "    arr = np.array(image)\n",
    "    return arr\n",
    "\n",
    "def array_to_bytes(arr):\n",
    " \n",
    "    \n",
    "    if arr.max() <= 1:\n",
    "        image = Image.fromarray((arr * 255).astype(np.uint8))\n",
    "    else:\n",
    "        image = Image.fromarray((arr).astype(np.uint8))\n",
    " \n",
    "    img_byte_arr = io.BytesIO()\n",
    "    image.save(img_byte_arr, format='jpeg')\n",
    "\n",
    "    img_byte_arr = img_byte_arr.getvalue()\n",
    "\n",
    "    return img_byte_arr\n",
    "\n",
    "\n",
    "state = {}\n",
    "\n",
    "state['image'] = np.ones((48,48))\n",
    "state['masked_image'] = np.copy(state['image'])\n",
    "state['upload_file'] = widgets.FileUpload(\n",
    "        accept='jpg',\n",
    "        multiple=False\n",
    "    )\n",
    "\n",
    "state['vae1'] = vae\n",
    "state['vae2'] = vae_task2\n",
    "\n",
    "\n",
    "\n",
    "image_np = np.array(state['image'])\n",
    "masked_image = np.copy(image_np)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "size_factor_slider = widgets.FloatSlider(value=0., min=0., max=.5, step=0.05, description='Size Factor:')\n",
    "start_y_slider = widgets.FloatSlider(value=0., min=0., max=1., step=0.05, description='Start X:')\n",
    "start_x_slider = widgets.FloatSlider(value=0., min=0., max=1., step=0.05, orientation='vertical' , description=' Start Y:')\n",
    "\n",
    "\n",
    "\n",
    "output_widget_1 = widgets.Output()\n",
    "output_widget_2 = widgets.Output()\n",
    "output_widget_3 = widgets.Output()\n",
    "\n",
    "\n",
    "\n",
    "def update_image(change):\n",
    "\n",
    "        start_x = start_x_slider.value\n",
    "        start_y = start_y_slider.value\n",
    "        size_factor = size_factor_slider.value\n",
    "\n",
    "\n",
    "        shape = state['image'].shape\n",
    "\n",
    "\n",
    "\n",
    "        masked_image = np.copy(state['image'])\n",
    "        mask_height = int(size_factor * shape[0])\n",
    "        mask_width = int(size_factor * shape[1])\n",
    "\n",
    "\n",
    "        start_x = int(start_x  *  (shape[0] - mask_height))\n",
    "        start_y = int(start_y  *  (shape[1] - mask_width))\n",
    "\n",
    "        end_x = int( start_x + mask_height )\n",
    "        end_y = int( start_y + mask_width )\n",
    "        masked_image[start_x:end_x , start_y:end_y] = 0\n",
    "\n",
    "        with output_widget_1:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "\n",
    "            display(widgets.Image(\n",
    "                      value=array_to_bytes(masked_image),\n",
    "                      format='jpeg',\n",
    "                      width=300,\n",
    "                      height=400,\n",
    "                  ))\n",
    "\n",
    "        with output_widget_2:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            display(widgets.Image(\n",
    "                      value=array_to_bytes(reconstruct_image(masked_image, state['vae1'])),\n",
    "                      format='jpeg',\n",
    "                      width=300,\n",
    "                      height=400,\n",
    "                  ))\n",
    "\n",
    "        with output_widget_3:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            display(widgets.Image(\n",
    "                      value=array_to_bytes(reconstruct_image(masked_image, state['vae2'])),\n",
    "                      format='jpg',\n",
    "                      width=300,\n",
    "                      height=400,\n",
    "                  ))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "start_x_slider.observe(update_image, names='value')\n",
    "start_y_slider.observe(update_image, names='value')\n",
    "size_factor_slider.observe(update_image, names='value')\n",
    "\n",
    "\n",
    "def show_file_upload(event):\n",
    "      display(state['upload_file'])\n",
    "\n",
    "\n",
    "def on_upload_change(change):\n",
    "\n",
    "    uploader = state['upload_file']\n",
    "    uploaded_file = uploader.value[0]['content'].tobytes()\n",
    "    state['image'] = to_array(uploaded_file)\n",
    "\n",
    "    update_image(\"\")\n",
    "\n",
    "\n",
    "state['upload_file'].observe(on_upload_change, names='value')\n",
    "\n",
    "\n",
    "upload_button = widgets.Button(description=\"upload a file\")\n",
    "upload_button.on_click(show_file_upload)\n",
    "image_load = VBox([output_widget_1, upload_button])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "internal = HBox([start_x_slider, image_load ])\n",
    "col1 = VBox([size_factor_slider, start_y_slider,   internal])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "col2 = VBox([output_widget_2])\n",
    "col3 = VBox([output_widget_3])\n",
    "\n",
    "\n",
    "\n",
    "main_box = HBox([col1, col2, col3])\n",
    "update_image(\"\")\n",
    "display(main_box)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17ce2d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
